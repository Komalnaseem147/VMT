{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd97d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_community.vectorstores import Qdrant as QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb import Client as ChromaClient\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863c1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "if not qdrant_url or not qdrant_api_key:\n",
    "    raise ValueError(\"set QDRANT_URL and QDRANT_API_KEY in .env file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98523107",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "chroma_api_key = os.getenv(\"CHROMA_API_KEY\")\n",
    "chroma_tenant = os.getenv(\"CHROMA_tenant\")\n",
    "HUGGING_FACE_API_TOKEN = os.getenv(\"HUGGING_FACE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d992cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"migration\")\n",
    "\n",
    "\n",
    "# Initialize Qdrant client for Qdrant Cloud\n",
    "qdrant_client = QdrantClient(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    "    prefer_grpc=True \n",
    ")\n",
    "logger.info(\"Qdrant Cloud client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "146bcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name=\"vector_db\"\n",
    "vector_dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "601f0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create collection if it doesn't exist\n",
    "if not qdrant_client.collection_exists(collection_name):\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=vector_dimension, distance=Distance.COSINE)\n",
    "        )\n",
    "logger.info(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce85c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Komal\\AppData\\Local\\Temp\\ipykernel_20520\\1143595057.py:14: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  extracted = load_pdf(data='E:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\data')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: 'E:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     text_chunk = text_splitter.split_documents(extracted_Data)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text_chunk\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m extracted = \u001b[43mload_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mE:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mAI\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mAgileForce\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mVector_db\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mVector-Database-Migration-Open-Source-Tool\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m test_chunks = text_split(extracted)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mload_pdf\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_pdf\u001b[39m(data):\n\u001b[32m      5\u001b[39m     loader = DirectoryLoader(data, glob=\u001b[33m\"\u001b[39m\u001b[33m*.pdf\u001b[39m\u001b[33m\"\u001b[39m, loader_cls=PyPDFLoader)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[39m, in \u001b[36mDirectoryLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Document]:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:123\u001b[39m, in \u001b[36mDirectoryLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m p = Path(\u001b[38;5;28mself\u001b[39m.path)\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p.exists():\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDirectory not found: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p.is_dir():\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected directory, got file: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Directory not found: 'E:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\data'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def text_split(extracted_Data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text_chunk = text_splitter.split_documents(extracted_Data)\n",
    "    return text_chunk\n",
    "\n",
    "extracted = load_pdf(data='E:\\AI\\AgileForce\\Vector_db\\Vector-Database-Migration-Open-Source-Tool\\data')\n",
    "test_chunks = text_split(extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed6446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    return HuggingFaceEndpointEmbeddings(\n",
    "        model=model_name,\n",
    "        huggingfacehub_api_token=HUGGING_FACE_API_TOKEN\n",
    "    )\n",
    "\n",
    "embeddings = download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5685ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Embed and upsert to qdrant\u001b[39;00m\n\u001b[32m      2\u001b[39m qdrant_store = QdrantVectorStore.from_documents(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     documents=\u001b[43mtest_chunks\u001b[49m,\n\u001b[32m      4\u001b[39m     embedding=embeddings,\n\u001b[32m      5\u001b[39m     collection_name=collection_name,\n\u001b[32m      6\u001b[39m     url=qdrant_url,\n\u001b[32m      7\u001b[39m     api_key=qdrant_api_key,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'test_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Embed and upsert to qdrant\n",
    "qdrant_store = QdrantVectorStore.from_documents(\n",
    "    documents=test_chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a508a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "chroma = PersistentClient(path=\"./chroma_store\")  \n",
    "chroma_collection = chroma.get_or_create_collection(name=\"migrated_vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client= chromadb.CloudClient(\n",
    "  api_key='ck-83UY8Q48K22Ac8U8SCsMCYz27fPdxg4Er73BGkBm5E8T',\n",
    "  tenant=chroma_tenant,\n",
    "  database='migrated_vectors'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32262fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"migrated_vectors\",  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31497144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_qdrant_vectors(client, collection_name, batch_size=100):\n",
    "    all_vectors = []\n",
    "    next_offset = None\n",
    "\n",
    "    while True:\n",
    "        points, next_offset = client.scroll(\n",
    "            collection_name=collection_name,\n",
    "            offset=next_offset,\n",
    "            limit=batch_size,\n",
    "            with_payload=True,\n",
    "            with_vectors=True\n",
    "        )\n",
    "        if not points:\n",
    "            break\n",
    "\n",
    "        for pt in points:\n",
    "            all_vectors.append({\n",
    "                \"id\": str(pt.id),\n",
    "                \"vector\": pt.vector,\n",
    "                \"metadata\": pt.payload or {}\n",
    "            })\n",
    "\n",
    "        if next_offset is None:\n",
    "            break\n",
    "    return all_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4116ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload to Chroma Cloud with Metadata Truncation\n",
    "\n",
    "def truncate_metadata(metadata, max_bytes=250):\n",
    "    \"\"\"Truncate metadata values to fit within Chroma's byte limits\"\"\"\n",
    "    cleaned_metadata = {}\n",
    "    \n",
    "    for key, value in metadata.items():\n",
    "        # Convert value to string\n",
    "        value_str = str(value) if not isinstance(value, str) else value\n",
    "        \n",
    "        # Check byte size\n",
    "        byte_size = len(value_str.encode('utf-8'))\n",
    "        \n",
    "        if byte_size > max_bytes:\n",
    "            # Truncate to fit within limit\n",
    "            truncated = value_str\n",
    "            while len(truncated.encode('utf-8')) > max_bytes:\n",
    "                truncated = truncated[:-10]  # Remove 10 chars at a time\n",
    "            truncated += \"...\"  # Add ellipsis to indicate truncation\n",
    "            cleaned_metadata[key] = truncated\n",
    "        else:\n",
    "            cleaned_metadata[key] = value_str\n",
    "    \n",
    "    return cleaned_metadata\n",
    "\n",
    "def chunked_upload(collection, vectors, batch_size=100):\n",
    "    \"\"\"Upload vectors with metadata size validation\"\"\"\n",
    "    total_uploaded = 0\n",
    "    \n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        chunk = vectors[i:i + batch_size]\n",
    "        ids = [v[\"id\"] for v in chunk]\n",
    "        embeddings = [v[\"vector\"] for v in chunk]\n",
    "        \n",
    "        # Clean metadata to fit Chroma limits\n",
    "        metadatas = [truncate_metadata(v[\"metadata\"]) for v in chunk]\n",
    "\n",
    "        try:\n",
    "            collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings,\n",
    "                metadatas=metadatas\n",
    "            )\n",
    "            total_uploaded += len(chunk)\n",
    "            print(f\"Uploaded {total_uploaded} / {len(vectors)} vectors âœ…\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch {i//batch_size + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return total_uploaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch vectors from Qdrant and upload to Chroma\n",
    "print(\"Fetching vectors from Qdrant...\")\n",
    "vectors = fetch_qdrant_vectors(qdrant_client, collection_name)\n",
    "print(f\"Found {len(vectors)} vectors to migrate\")\n",
    "\n",
    "print(\"\\nUploading to Chroma Cloud with metadata truncation...\")\n",
    "uploaded_count = chunked_upload(collection, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74109e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[vectors[0][\"vector\"]],\n",
    "    n_results=3\n",
    ")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check metadata sizes to identify the problem\n",
    "\n",
    "def check_metadata_sizes(vectors):\n",
    "    \"\"\"Check metadata sizes and identify problematic entries\"\"\"\n",
    "    problematic_entries = []\n",
    "    \n",
    "    for i, vector in enumerate(vectors[:10]):  # Check first 10 for analysis\n",
    "        metadata = vector.get(\"metadata\", {})\n",
    "        \n",
    "        for key, value in metadata.items():\n",
    "            # Convert to string to measure byte size\n",
    "            value_str = str(value) if not isinstance(value, str) else value\n",
    "            byte_size = len(value_str.encode('utf-8'))\n",
    "            \n",
    "            print(f\"Vector {i}, Key: '{key}', Size: {byte_size} bytes\")\n",
    "            \n",
    "            if byte_size > 256:\n",
    "                problematic_entries.append({\n",
    "                    'vector_index': i,\n",
    "                    'key': key,\n",
    "                    'size': byte_size,\n",
    "                    'value_preview': value_str[:100] + \"...\" if len(value_str) > 100 else value_str\n",
    "                })\n",
    "    \n",
    "    return problematic_entries\n",
    "\n",
    "# Check the metadata sizes\n",
    "problematic = check_metadata_sizes(vectors)\n",
    "print(f\"\\nFound {len(problematic)} problematic metadata entries:\")\n",
    "for entry in problematic:\n",
    "    print(f\"Vector {entry['vector_index']}: '{entry['key']}' = {entry['size']} bytes\")\n",
    "    print(f\"Preview: {entry['value_preview']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection_info = collection.get()\n",
    "print(f\" Migration Successful!\")\n",
    "print(f\"Total vectors in Chroma: {len(collection_info['ids'])}\")\n",
    "\n",
    "# Show a sample of the truncated metadata\n",
    "if collection_info['metadatas']:\n",
    "    sample_metadata = collection_info['metadatas'][0]\n",
    "    print(f\"\\nSample metadata (truncated to fit Chroma limits):\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        byte_size = len(str(value).encode('utf-8'))\n",
    "        print(f\"  {key}: {byte_size} bytes - {str(value)[:50]}{'...' if len(str(value)) > 50 else ''}\")\n",
    "        \n",
    "print(f\" Successfully migrated {len(collection_info['ids'])} vectors from Qdrant to Chroma!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bea90c",
   "metadata": {},
   "source": [
    "Chroma to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not qdrant_url or not qdrant_api_key:\n",
    "    raise ValueError(\"Set QDRANT_URL and QDRANT_API_KEY in .env file\")\n",
    "if not chroma_api_key or not chroma_tenant:\n",
    "    raise ValueError(\"Set CHROMA_API_KEY, CHROMA_TENANT, and CHROMA_DATABASE in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41142d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Setup logging and initialize clients\n",
    "logger = logging.getLogger(\"migration\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    "    prefer_grpc=True\n",
    ")\n",
    "logger.info(\"Qdrant Cloud client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Setup collections\n",
    "chroma_collection_name = \"migrated_vectors\"\n",
    "qdrant_collection_name = \"chroma_to_qdrant\"\n",
    "vector_dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a814c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Qdrant collection if it doesn't exist\n",
    "if not qdrant_client.collection_exists(qdrant_collection_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=qdrant_collection_name,\n",
    "        vectors_config=VectorParams(size=vector_dimension, distance=Distance.COSINE)\n",
    "    )\n",
    "logger.info(f\"Created Qdrant collection: {qdrant_collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Chroma collection\n",
    "chroma_collection = chroma_client.get_or_create_collection(name=chroma_collection_name)\n",
    "logger.info(f\"Accessed Chroma collection: {chroma_collection_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5befb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch vectors from Chroma\n",
    "def fetch_chroma_vectors(collection, batch_size=100):\n",
    "    \"\"\"Fetch all vectors from Chroma collection\"\"\"\n",
    "    all_vectors = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        results = collection.get(\n",
    "            include=[\"embeddings\", \"metadatas\"],\n",
    "            limit=batch_size,\n",
    "            offset=offset\n",
    "        )\n",
    "        \n",
    "        if not results['ids']:\n",
    "            break\n",
    "\n",
    "        for i in range(len(results['ids'])):\n",
    "            all_vectors.append({\n",
    "                \"id\": results['ids'][i],\n",
    "                \"vector\": results['embeddings'][i],\n",
    "                \"metadata\": results['metadatas'][i] or {}\n",
    "            })\n",
    "\n",
    "        offset += batch_size\n",
    "        logger.info(f\"Fetched {len(all_vectors)} vectors so far...\")\n",
    "\n",
    "    return all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata truncation function\n",
    "def truncate_metadata(metadata, max_bytes=250):\n",
    "    \"\"\"Truncate metadata values to fit within Qdrant's byte limits\"\"\"\n",
    "    cleaned_metadata = {}\n",
    "    \n",
    "    for key, value in metadata.items():\n",
    "        # Convert value to string\n",
    "        value_str = str(value) if not isinstance(value, str) else value\n",
    "        \n",
    "        # Check byte size\n",
    "        byte_size = len(value_str.encode('utf-8'))\n",
    "        \n",
    "        if byte_size > max_bytes:\n",
    "            # Truncate to fit within limit\n",
    "            truncated = value_str\n",
    "            while len(truncated.encode('utf-8')) > max_bytes:\n",
    "                truncated = truncated[:-10]  # Remove 10 chars at a time\n",
    "            truncated += \"...\"  # Add ellipsis to indicate truncation\n",
    "            cleaned_metadata[key] = truncated\n",
    "        else:\n",
    "            cleaned_metadata[key] = value_str\n",
    "    \n",
    "    return cleaned_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload vectors to Qdrant\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "def chunked_upload_to_qdrant(client, collection_name, vectors, batch_size=100):\n",
    "    \"\"\"Upload vectors to Qdrant with metadata size validation\"\"\"\n",
    "    total_uploaded = 0\n",
    "    \n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        chunk = vectors[i:i + batch_size]\n",
    "        points = []\n",
    "        \n",
    "        for v in chunk:\n",
    "            cleaned_metadata = truncate_metadata(v[\"metadata\"])\n",
    "            points.append(PointStruct(\n",
    "                id=v[\"id\"],\n",
    "                vector=v[\"vector\"],\n",
    "                payload=cleaned_metadata\n",
    "            ))\n",
    "\n",
    "        try:\n",
    "            client.upsert(\n",
    "                collection_name=collection_name,\n",
    "                points=points\n",
    "            )\n",
    "            total_uploaded += len(chunk)\n",
    "            logger.info(f\"Uploaded {total_uploaded} / {len(vectors)} vectors to Qdrant \")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error uploading batch {i//batch_size + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return total_uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute migration\n",
    "logger.info(\"Fetching vectors from Chroma...\")\n",
    "vectors = fetch_chroma_vectors(chroma_collection)\n",
    "logger.info(f\"Found {len(vectors)} vectors to migrate\")\n",
    "\n",
    "logger.info(\"\\nUploading to Qdrant with metadata truncation...\")\n",
    "uploaded_count = chunked_upload_to_qdrant(qdrant_client, qdrant_collection_name, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection_info = qdrant_client.get_collection(qdrant_collection_name)\n",
    "print(f\"Migration Successful!\")\n",
    "print(f\"Total vectors in Qdrant: {collection_info.vectors_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectors:\n",
    "    sample_vector = vectors[0]\n",
    "    print(f\"\\nSample metadata (truncated to fit Qdrant limits):\")\n",
    "    cleaned_metadata = truncate_metadata(sample_vector['metadata'])\n",
    "    for key, value in cleaned_metadata.items():\n",
    "        byte_size = len(str(value).encode('utf-8'))\n",
    "        print(f\"  {key}: {byte_size} bytes - {str(value)[:50]}{'...' if len(str(value)) > 50 else ''}\")\n",
    "        \n",
    "print(f\"Successfully migrated {uploaded_count} vectors from Chroma to Qdrant!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
